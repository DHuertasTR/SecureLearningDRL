{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gym import Env\r\n",
    "from gym.spaces import Discrete, Box\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import pandas as pd\r\n",
    "import tensorflow\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Flatten\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from rl.agents import DQNAgent\r\n",
    "from rl.policy import BoltzmannQPolicy\r\n",
    "from rl.memory import SequentialMemory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data=pd.read_csv('datasets/malicious_data_generated.csv')\r\n",
    "npdata=data.to_numpy()\r\n",
    "malData=np.copy(npdata)\r\n",
    "print(type(malData[1,:]))\r\n",
    "print(malData[:1].shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MalwareEnv(Env):\r\n",
    "    def __init__(self):\r\n",
    "        # Actions we can take, decrease, increse, none\r\n",
    "        self.action_space = Discrete(21)\r\n",
    "        # max-min array\r\n",
    "        self.observation_space = Box(np.asarray([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]),np.asarray([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\r\n",
    "        # Set start \r\n",
    "        self.state = np.asarray(malData[random.randint(0,499),:])\r\n",
    "        \r\n",
    "        # Set time \r\n",
    "        self.length = 60\r\n",
    "        \r\n",
    "    def step(self, action):\r\n",
    "        # Apply action for each state\r\n",
    "        if(action<10):\r\n",
    "            if(action==0):\r\n",
    "                self.state[0]=self.state[0]+1\r\n",
    "            elif(action==1):\r\n",
    "                 self.state[1]=self.state[1]+1\r\n",
    "            elif(action==2):\r\n",
    "                 self.state[2]=self.state[2]+1\r\n",
    "            elif(action==3):\r\n",
    "                 self.state[3]=self.state[3]+1\r\n",
    "            elif(action==4):\r\n",
    "                 self.state[4]=self.state[4]+1\r\n",
    "            elif(action==5):\r\n",
    "                 self.state[5]=self.state[5]+1\r\n",
    "            elif(action==6):\r\n",
    "                 self.state[6]=self.state[6]+1\r\n",
    "            elif(action==7):\r\n",
    "                 self.state[7]=self.state[7]+1\r\n",
    "            elif(action==8):\r\n",
    "                 self.state[8]=self.state[8]+1\r\n",
    "            else:\r\n",
    "                 self.state[9]=self.state[9]+1                     \r\n",
    "        else:\r\n",
    "            if(action==10):\r\n",
    "                self.state[0]+=self.state[0]-1\r\n",
    "            elif(action==11):\r\n",
    "                 self.state[1]+=self.state[1]-1\r\n",
    "            elif(action==12):\r\n",
    "                 self.state[2]+=self.state[2]-1\r\n",
    "            elif(action==13):\r\n",
    "                 self.state[3]+=self.state[3]-1\r\n",
    "            elif(action==14):\r\n",
    "                 self.state[4]+=self.state[4]-1\r\n",
    "            elif(action==15):\r\n",
    "                 self.state[5]+=self.state[5]-1\r\n",
    "            elif(action==16):\r\n",
    "                 self.state[6]+=self.state[6]-1\r\n",
    "            elif(action==17):\r\n",
    "                 self.state[7]+=self.state[7]-1\r\n",
    "            elif(action==18):\r\n",
    "                 self.state[8]+=self.state[8]-1\r\n",
    "            else:\r\n",
    "                 self.state[9]+=self.state[9]-1  \r\n",
    "        \r\n",
    "        self.length -= 1 \r\n",
    "            \r\n",
    "        \r\n",
    "        # Calculate reward in ranges\r\n",
    "        rewardMulti=0 \r\n",
    "        \r\n",
    "        if(self.state[0]>=-0.290698 and self.state[0]<=-133.441860):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[1]>=0 and self.state[1]<=1184):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[2]>=-0.666667 and self.state[2]<=10.666667):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[3]>=-0.312383 and self.state[3]<=109.259173):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[4]>=0 and self.state[4]<=30):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[5]>=-0.322 and self.state[5]<=127.488889):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[6]>=-0.282353 and self.state[6]<=147.976471):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[7]>=-0.164688 and self.state[7]<=715.616633):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[8]>=-0.324081 and self.state[8]<=106.407677):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[9]>=-0.750000 and self.state[9]<=227.5):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "                 \r\n",
    "        if(rewardMulti==0):\r\n",
    "            reward=-1\r\n",
    "        else:\r\n",
    "            reward=rewardMulti\r\n",
    "                 \r\n",
    "        \r\n",
    "        # Check if is done\r\n",
    "        if self.length <= 0: \r\n",
    "            done = True\r\n",
    "        else:\r\n",
    "            done = False\r\n",
    "        \r\n",
    "        \r\n",
    "        info = {}\r\n",
    "        \r\n",
    "        # Return step information\r\n",
    "        return self.state, reward, done, info\r\n",
    "\r\n",
    "    def render(self):\r\n",
    "        pass\r\n",
    "    \r\n",
    "    def reset(self):\r\n",
    "        # Reset \r\n",
    "        self.state = malData[random.randint(0,499),:]\r\n",
    "        # Reset time\r\n",
    "        self.length = 60 \r\n",
    "        return self.state"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\r\n",
    "import random\r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from collections import deque\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "env = gym.make('CartPole-v0')\r\n",
    "env.seed(0)\r\n",
    "np.random.seed(0)\r\n",
    "\r\n",
    "\r\n",
    "class DQN:\r\n",
    "\r\n",
    "    \"\"\" Implementation of deep q learning algorithm \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, action_space, state_space):\r\n",
    "\r\n",
    "        self.action_space = action_space\r\n",
    "        self.state_space = state_space\r\n",
    "        self.epsilon = 1\r\n",
    "        self.gamma = .95\r\n",
    "        self.batch_size = 64\r\n",
    "        self.epsilon_min = .01\r\n",
    "        self.epsilon_decay = .995\r\n",
    "        self.learning_rate = 0.001\r\n",
    "        self.memory = deque(maxlen=10000)\r\n",
    "        self.model = self.build_model()\r\n",
    "\r\n",
    "    def build_model(self):\r\n",
    "\r\n",
    "        model = Sequential()\r\n",
    "        model.add(Dense(24, input_shape=(self.state_space,), activation='relu'))\r\n",
    "        model.add(Dense(24, activation='relu'))\r\n",
    "        model.add(Dense(self.action_space, activation='linear'))\r\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\r\n",
    "        return model\r\n",
    "\r\n",
    "    def remember(self, state, action, reward, next_state, done):\r\n",
    "        self.memory.append((state, action, reward, next_state, done))\r\n",
    "\r\n",
    "    def act(self, state):\r\n",
    "\r\n",
    "        if np.random.rand() <= self.epsilon:\r\n",
    "            return random.randrange(self.action_space)\r\n",
    "        act_values = self.model.predict(state)\r\n",
    "        return np.argmax(act_values[0])\r\n",
    "\r\n",
    "    def replay(self):\r\n",
    "\r\n",
    "        if len(self.memory) < self.batch_size:\r\n",
    "            return\r\n",
    "\r\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\r\n",
    "        states = np.array([i[0] for i in minibatch])\r\n",
    "        actions = np.array([i[1] for i in minibatch])\r\n",
    "        rewards = np.array([i[2] for i in minibatch])\r\n",
    "        next_states = np.array([i[3] for i in minibatch])\r\n",
    "        dones = np.array([i[4] for i in minibatch])\r\n",
    "\r\n",
    "        states = np.squeeze(states)\r\n",
    "        next_states = np.squeeze(next_states)\r\n",
    "\r\n",
    "        targets = rewards + self.gamma*(np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones)\r\n",
    "        targets_full = self.model.predict_on_batch(states)\r\n",
    "\r\n",
    "        ind = np.array([i for i in range(self.batch_size)])\r\n",
    "        targets_full[[ind], [actions]] = targets\r\n",
    "\r\n",
    "        self.model.fit(states, targets_full, epochs=1, verbose=0)\r\n",
    "        if self.epsilon > self.epsilon_min:\r\n",
    "            self.epsilon *= self.epsilon_decay\r\n",
    "\r\n",
    "\r\n",
    "def train_dqn(episode):\r\n",
    "\r\n",
    "    loss = []\r\n",
    "    agent = DQN(env.action_space.n, env.observation_space.shape[0])\r\n",
    "    for e in range(episode):\r\n",
    "        state = env.reset()\r\n",
    "        state = np.reshape(state, (1, 4))\r\n",
    "        score = 0\r\n",
    "        max_steps = 1000\r\n",
    "        for i in range(max_steps):\r\n",
    "            env.render()\r\n",
    "            action = agent.act(state)\r\n",
    "            next_state, reward, done, _ = env.step(action)\r\n",
    "            score += reward\r\n",
    "            next_state = np.reshape(next_state, (1, 4))\r\n",
    "            agent.remember(state, action, reward, next_state, done)\r\n",
    "            state = next_state\r\n",
    "            agent.replay()\r\n",
    "            if done:\r\n",
    "                print(\"episode: {}/{}, score: {}\".format(e, episode, score))\r\n",
    "                break\r\n",
    "        loss.append(score)\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "def random_policy(episode, step):\r\n",
    "\r\n",
    "    for i_episode in range(episode):\r\n",
    "        env.reset()\r\n",
    "        for t in range(step):\r\n",
    "            env.render()\r\n",
    "            action = env.action_space.sample()\r\n",
    "            state, reward, done, info = env.step(action)\r\n",
    "            if done:\r\n",
    "                print(\"Episode finished after {} timesteps\".format(t+1))\r\n",
    "                break\r\n",
    "            print(\"Starting next episode\")\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "\r\n",
    "    ep = 25\r\n",
    "    loss = train_dqn(ep)\r\n",
    "    plt.plot([i+1 for i in range(0, ep, 2)], loss[::2])\r\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 0/25, score: 50.0\n",
      "episode: 1/25, score: 57.0\n",
      "episode: 2/25, score: 25.0\n",
      "episode: 3/25, score: 18.0\n",
      "episode: 4/25, score: 16.0\n",
      "episode: 5/25, score: 12.0\n",
      "episode: 6/25, score: 10.0\n",
      "episode: 7/25, score: 27.0\n",
      "episode: 8/25, score: 15.0\n",
      "episode: 9/25, score: 21.0\n",
      "episode: 10/25, score: 8.0\n",
      "episode: 11/25, score: 21.0\n",
      "episode: 12/25, score: 12.0\n",
      "episode: 13/25, score: 12.0\n",
      "episode: 14/25, score: 23.0\n",
      "episode: 15/25, score: 9.0\n",
      "episode: 16/25, score: 12.0\n",
      "episode: 17/25, score: 8.0\n",
      "episode: 18/25, score: 13.0\n",
      "episode: 19/25, score: 10.0\n",
      "episode: 20/25, score: 8.0\n",
      "episode: 21/25, score: 42.0\n",
      "episode: 22/25, score: 21.0\n",
      "episode: 23/25, score: 36.0\n",
      "episode: 24/25, score: 84.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pgd': conda)"
  },
  "interpreter": {
   "hash": "cabac2954cf654a7c1a0a2cb4143c0d9684498a99fac728f492c82ef13f7b48d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}