{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from gym import Env\r\n",
    "from gym.spaces import Discrete, Box\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import pandas as pd\r\n",
    "import tensorflow\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Flatten\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from rl.agents import DQNAgent\r\n",
    "from rl.policy import BoltzmannQPolicy\r\n",
    "from rl.memory import SequentialMemory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data=pd.read_csv('datasets/malicious_data_generated.csv')\r\n",
    "npdata=data.to_numpy()\r\n",
    "malData=np.copy(npdata)\r\n",
    "print(type(malData[1,:]))\r\n",
    "print(malData[:1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 10)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class MalwareEnv():\r\n",
    "    def __init__(self):\r\n",
    "        # Actions we can take, decrease, increse, none\r\n",
    "        self.action_space = Discrete(21)\r\n",
    "        # max-min array\r\n",
    "        self.observation_space = Box(np.asarray([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]),np.asarray([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\r\n",
    "        # Set start \r\n",
    "        self.state = np.asarray(malData[random.randint(0,499),:])\r\n",
    "        \r\n",
    "        # Set time \r\n",
    "        self.length = 60\r\n",
    "        \r\n",
    "    def step(self, action):\r\n",
    "        # Apply action for each state\r\n",
    "        if(action<10):\r\n",
    "            if(action==0):\r\n",
    "                self.state[0]=self.state[0]+1\r\n",
    "            elif(action==1):\r\n",
    "                 self.state[1]=self.state[1]+1\r\n",
    "            elif(action==2):\r\n",
    "                 self.state[2]=self.state[2]+1\r\n",
    "            elif(action==3):\r\n",
    "                 self.state[3]=self.state[3]+1\r\n",
    "            elif(action==4):\r\n",
    "                 self.state[4]=self.state[4]+1\r\n",
    "            elif(action==5):\r\n",
    "                 self.state[5]=self.state[5]+1\r\n",
    "            elif(action==6):\r\n",
    "                 self.state[6]=self.state[6]+1\r\n",
    "            elif(action==7):\r\n",
    "                 self.state[7]=self.state[7]+1\r\n",
    "            elif(action==8):\r\n",
    "                 self.state[8]=self.state[8]+1\r\n",
    "            else:\r\n",
    "                 self.state[9]=self.state[9]+1                     \r\n",
    "        else:\r\n",
    "            if(action==10):\r\n",
    "                self.state[0]+=self.state[0]-1\r\n",
    "            elif(action==11):\r\n",
    "                 self.state[1]+=self.state[1]-1\r\n",
    "            elif(action==12):\r\n",
    "                 self.state[2]+=self.state[2]-1\r\n",
    "            elif(action==13):\r\n",
    "                 self.state[3]+=self.state[3]-1\r\n",
    "            elif(action==14):\r\n",
    "                 self.state[4]+=self.state[4]-1\r\n",
    "            elif(action==15):\r\n",
    "                 self.state[5]+=self.state[5]-1\r\n",
    "            elif(action==16):\r\n",
    "                 self.state[6]+=self.state[6]-1\r\n",
    "            elif(action==17):\r\n",
    "                 self.state[7]+=self.state[7]-1\r\n",
    "            elif(action==18):\r\n",
    "                 self.state[8]+=self.state[8]-1\r\n",
    "            else:\r\n",
    "                 self.state[9]+=self.state[9]-1  \r\n",
    "        \r\n",
    "        self.length -= 1 \r\n",
    "            \r\n",
    "        \r\n",
    "        # Calculate reward in ranges\r\n",
    "        rewardMulti=0 \r\n",
    "        \r\n",
    "        if(self.state[0]>=-0.290698 and self.state[0]<=-133.441860):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[1]>=0 and self.state[1]<=1184):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[2]>=-0.666667 and self.state[2]<=10.666667):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[3]>=-0.312383 and self.state[3]<=109.259173):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[4]>=0 and self.state[4]<=30):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[5]>=-0.322 and self.state[5]<=127.488889):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[6]>=-0.282353 and self.state[6]<=147.976471):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[7]>=-0.164688 and self.state[7]<=715.616633):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[8]>=-0.324081 and self.state[8]<=106.407677):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "        elif(self.state[9]>=-0.750000 and self.state[9]<=227.5):\r\n",
    "                 rewardMulti=rewardMulti+1\r\n",
    "                 \r\n",
    "        if(rewardMulti==0):\r\n",
    "            reward=-1\r\n",
    "        else:\r\n",
    "            reward=rewardMulti\r\n",
    "                 \r\n",
    "        \r\n",
    "        # Check if is done\r\n",
    "        if self.length <= 0: \r\n",
    "            done = True\r\n",
    "        else:\r\n",
    "            done = False\r\n",
    "        \r\n",
    "        \r\n",
    "        info = {}\r\n",
    "        \r\n",
    "        # Return step information\r\n",
    "        return self.state, reward, done, info\r\n",
    "\r\n",
    "    def render(self):\r\n",
    "        pass\r\n",
    "    \r\n",
    "    def reset(self):\r\n",
    "        # Reset \r\n",
    "        self.state = malData[random.randint(0,499),:]\r\n",
    "        # Reset time\r\n",
    "        self.length = 60 \r\n",
    "        return self.state"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import gym\r\n",
    "import random\r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from collections import deque\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "env = gym.make('CartPole-v0')\r\n",
    "env.seed(0)\r\n",
    "np.random.seed(0)\r\n",
    "\r\n",
    "\r\n",
    "class DQN:\r\n",
    "\r\n",
    "    \"\"\" Implementation of deep q learning algorithm \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, action_space, state_space):\r\n",
    "\r\n",
    "        self.action_space = action_space\r\n",
    "        self.state_space = state_space\r\n",
    "        self.epsilon = 1\r\n",
    "        self.gamma = .95\r\n",
    "        self.batch_size = 64\r\n",
    "        self.epsilon_min = .01\r\n",
    "        self.epsilon_decay = .995\r\n",
    "        self.learning_rate = 0.001\r\n",
    "        self.memory = deque(maxlen=10000)\r\n",
    "        self.model = self.build_model()\r\n",
    "\r\n",
    "    def build_model(self):\r\n",
    "\r\n",
    "        model = Sequential()\r\n",
    "        model.add(Dense(24, input_shape=(self.state_space,), activation='relu'))\r\n",
    "        model.add(Dense(24, activation='relu'))\r\n",
    "        model.add(Dense(self.action_space, activation='linear'))\r\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\r\n",
    "        return model\r\n",
    "\r\n",
    "    def remember(self, state, action, reward, next_state, done):\r\n",
    "        self.memory.append((state, action, reward, next_state, done))\r\n",
    "\r\n",
    "    def act(self, state):\r\n",
    "\r\n",
    "        if np.random.rand() <= self.epsilon:\r\n",
    "            return random.randrange(self.action_space)\r\n",
    "        act_values = self.model.predict(state)\r\n",
    "        return np.argmax(act_values[0])\r\n",
    "\r\n",
    "    def replay(self):\r\n",
    "\r\n",
    "        if len(self.memory) < self.batch_size:\r\n",
    "            return\r\n",
    "\r\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\r\n",
    "        states = np.array([i[0] for i in minibatch])\r\n",
    "        actions = np.array([i[1] for i in minibatch])\r\n",
    "        rewards = np.array([i[2] for i in minibatch])\r\n",
    "        next_states = np.array([i[3] for i in minibatch])\r\n",
    "        dones = np.array([i[4] for i in minibatch])\r\n",
    "\r\n",
    "        states = np.squeeze(states)\r\n",
    "        next_states = np.squeeze(next_states)\r\n",
    "\r\n",
    "        targets = rewards + self.gamma*(np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones)\r\n",
    "        targets_full = self.model.predict_on_batch(states)\r\n",
    "\r\n",
    "        ind = np.array([i for i in range(self.batch_size)])\r\n",
    "        targets_full[[ind], [actions]] = targets\r\n",
    "\r\n",
    "        self.model.fit(states, targets_full, epochs=1, verbose=0)\r\n",
    "        if self.epsilon > self.epsilon_min:\r\n",
    "            self.epsilon *= self.epsilon_decay\r\n",
    "\r\n",
    "\r\n",
    "def train_dqn(episode):\r\n",
    "\r\n",
    "    loss = []\r\n",
    "    agent = DQN(env.action_space.n, env.observation_space.shape[0])\r\n",
    "    for e in range(episode):\r\n",
    "        state = env.reset()\r\n",
    "        state = np.reshape(state, (1, 4))\r\n",
    "        score = 0\r\n",
    "        max_steps = 1000\r\n",
    "        for i in range(max_steps):\r\n",
    "            env.render()\r\n",
    "            action = agent.act(state)\r\n",
    "            next_state, reward, done, _ = env.step(action)\r\n",
    "            score += reward\r\n",
    "            next_state = np.reshape(next_state, (1, 4))\r\n",
    "            agent.remember(state, action, reward, next_state, done)\r\n",
    "            state = next_state\r\n",
    "            agent.replay()\r\n",
    "            if done:\r\n",
    "                print(\"episode: {}/{}, score: {}\".format(e, episode, score))\r\n",
    "                break\r\n",
    "        loss.append(score)\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "def random_policy(episode, step):\r\n",
    "\r\n",
    "    for i_episode in range(episode):\r\n",
    "        env.reset()\r\n",
    "        for t in range(step):\r\n",
    "            env.render()\r\n",
    "            action = env.action_space.sample()\r\n",
    "            state, reward, done, info = env.step(action)\r\n",
    "            if done:\r\n",
    "                print(\"Episode finished after {} timesteps\".format(t+1))\r\n",
    "                break\r\n",
    "            print(\"Starting next episode\")\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "\r\n",
    "    ep = 25\r\n",
    "    loss = train_dqn(ep)\r\n",
    "    plt.plot([i+1 for i in range(0, ep, 2)], loss[::2])\r\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 0/25, score: 20.0\n",
      "episode: 1/25, score: 26.0\n",
      "WARNING:tensorflow:From D:\\programas\\anaco\\envs\\pgd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "episode: 2/25, score: 57.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 3/25, score: 39.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 4/25, score: 16.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 5/25, score: 13.0\n",
      "episode: 6/25, score: 9.0\n",
      "episode: 7/25, score: 12.0\n",
      "episode: 8/25, score: 11.0\n",
      "episode: 9/25, score: 16.0\n",
      "episode: 10/25, score: 9.0\n",
      "episode: 11/25, score: 22.0\n",
      "episode: 12/25, score: 10.0\n",
      "episode: 13/25, score: 9.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "episode: 14/25, score: 10.0\n",
      "episode: 15/25, score: 8.0\n",
      "episode: 16/25, score: 11.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 17/25, score: 9.0\n",
      "episode: 18/25, score: 11.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 19/25, score: 21.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 20/25, score: 17.0\n",
      "episode: 21/25, score: 22.0\n",
      "episode: 22/25, score: 17.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 23/25, score: 24.0\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "episode: 24/25, score: 33.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhHUlEQVR4nO3da3Rc5X3v8e+jmyXNyBdpRhdfpbFlQzB3mUJIEyAJsZM05FKTZKXEEBInpz2ryVknK6F90eacs3pWmrZZvayVJpSb05SAXaCQNPhASMilAWMZAzYx1viG5YtmRpItz8iWZEnPeTGzZWFGkSzPzN575vdZizWa8Uj72Qz8/OjZ//38jbUWERHxnzK3ByAiIrOjABcR8SkFuIiITynARUR8SgEuIuJTFYU8WCgUsq2trYU8pIiI7+3YsaPXWhs+//WCBnhrayudnZ2FPKSIiO8ZY97M9rqWUEREfEoBLiLiUwpwERGfUoCLiPiUAlxExKcU4CIiPqUAFxHxKQV4xti45ZGXDjMyOu72UEREZkQBnvGb/b3c8/guntsTc3soIiIzogDP2NuTBOBA76DLIxERmRkFeMa+eAqA/YmUyyMREZkZBXhGVyw9Az+oGbiI+IQCHLDWEs3MwA8kBlGfUBHxAwU4EDs1THJolGUNtQycOcuJ02fdHpKIyLQU4JxbPll7WTMAB7QOLiI+oACHieWTW50A1zq4iPiAAhyIxpI0BKq4cvE8KssNBxIKcBHxPgU46Rn4isYgFeVlLK2v5WCvllBExPtKPsCttXTFkqxsqgOgLRRUKaGI+ELJB7hTgdLeFARgeTjAob7TjI2rlFBEvK3kAzwaT1egtDc6M/AAI6PjHDt5xs1hiYhMq+QDvCuWXu9emZmBR8LpR91SLyJeV/IBHo0lqQ9U0RCcA6Rn4KBb6kXE+xTg8RTtjcGJ56FgFXXVFSolFBHPK+kAP78CBcAYQyQU0AxcRDyvpAM8nnxrBYqjLRTQ7fQi4nklHeDOHihOBYojEg5ybGCIMyNjbgxLRGRGSjzA07PsbDNw0IVMEfG2kg7wffF0BUooU4HiiIQV4CLifSUd4F2xt1agOM7NwLUOLiLeVbIBbq0lGku+bfkEoLaqgpZ51SolFBFPK9kAjyeHOTU0+pYSwsnaQgHtCy4inlayAe5UoKzIsoQC6XXwA4mU+mOKiGeVbIBHJ/ZAmWoGHuTU0Cj9gyOFHJaIyIzNKMCNMYeMMbuMMa8YYzozr9UbY541xkQzjwvyO9Tcik5RgeJwKlG0jCIiXnUhM/CbrbVXWWs7Ms/vAZ6z1rYDz2We+0ZXLDXl8glAxKlE0YVMEfGoi1lCuQ3YlPl6E/DRix5NgTgVKCuzVKA4Fs2vobLcsF+lhCLiUTMNcAs8Y4zZYYzZmHmtyVp7HCDz2JjtG40xG40xncaYzkQicfEjzgGnAuX8W+gnqygvY1lDQDNwEfGsihm+70Zr7TFjTCPwrDHmjZkewFp7L3AvQEdHhydKOqJT3EJ/PpUSioiXzWgGbq09lnmMA08A1wExY0wLQOYxnq9B5ppTQjhVBYojEg7wZt+g+mOKiCdNG+DGmIAxps75GrgV2A08BWzIvG0D8GS+Bplr0XiSBbWVNASqfuf7IqEAZ8csR06cLtDIRERmbiZLKE3AE8YY5/0PW2u3GmO2A5uNMXcDh4H1+RtmbkVjKdqb6sic05Sc/pgHegdZ1hAoxNBERGZs2gC31h4Arszyeh/w3nwMKp+cLjwfuWrhtO9tm1RKePOqfI9MROTClNydmIkZVKA4GgJVzK2u4IBKCUXEg0ouwKdq4pCNMYa2cFD7gouIJ5VggGdvozaV5aGAtpUVEU8quQCPxlMsqK0kFPzdFSiOtlCA4wNDnB4ZzfPIREQuTOkFeCw5owoUh1OJomUUEfGakgpwpwIlWxu1qajBsYh4VUkFeGKaLjzZtIZqAbQOLiKeU1IBPlGBcgEz8NqqChbOq9YMXEQ8p6QCPBrPVKBcwAwcoC3TXk1ExEtKKsC7YhdWgeKIhIIc6B1Uf0wR8ZSSCvBoLEl748wrUBxtoQDJoVH61B9TRDykZALcWks0nprRHZjnm+iPqQuZIuIhJRPgieQwA2fOXtAFTEck5NSCax1cRLyjZAI8Gk+H74WUEDoWLaihqrxMM3AR8ZSSCfCJPVBmEeDlZYZlDbVqryYinlJCAZ5i/iwqUBwRlRKKiMeUTIDviydZOYsKFEdbKMjh/tOMjo3neGQiIrNTEgGe3gMlxYpZVKA4zvXHPJPDkYmIzF5JBLhTgbJyFhUoDqeUULfUi4hXlESAX0wFisPZlXC/1sFFxCNKIsCdCpSLWUKpD1Qxr6ZSM3AR8YySCPBoPF2BEg7OmfXPMMbQpvZqIuIhpRHgsYurQHFEwgHNwEXEM4o+wHNRgeKIhAL0nBpicFj9MUXEfUUf4InUxVegONQfU0S8pOgDPOp04bmIChSH+mOKiJcUfYCf2wPl4mfgToDrQqaIeEHRB3guKlAc1ZXlLJpfo21lRcQTij/AY0naG4MXXYHiaAsFtCuhiHhCUQe4U4GSi/VvRyQc4GBC/TFFxH1FHeBOBcpsuvBMpS0UIDk8SiI1nLOfKSIyG0Ud4E4FysXsgXK+iVJCXcgUEZfNOMCNMeXGmJ3GmB9nntcbY541xkQzjwvyN8zZieawAsURcSpRtA4uIi67kBn4l4E9k57fAzxnrW0Hnss895SueIp5NbmpQHEsnF9DVUWZasFFxHUzCnBjzGLgQ8B9k16+DdiU+XoT8NGcjiwH9sVSrGzKXQUKpPtjtjbUqhZcRFw30xn43wNfAyb3E2uy1h4HyDw2ZvtGY8xGY0ynMaYzkUhczFgviLWWrniSFY25W/92REJBDqgWXERcNm2AG2M+DMSttTtmcwBr7b3W2g5rbUc4HJ7Nj5iVRGqYk6fPsjKH69+OtnCAw33qjyki7prJDPxG4CPGmEPAI8AtxpgfADFjTAtA5jGet1HOwr48VKA4IqEAo+OWbvXHFBEXTRvg1to/s9Yutta2Ap8Cfmat/SPgKWBD5m0bgCfzNspZmNgDJYc14I5z/TG1jCIi7rmYOvBvAu83xkSB92eee8ZEBUpd7ipQHG2h9F8KupApIm6quJA3W2ufB57PfN0HvDf3Q8qNfbFUTvdAmaw+UMX82krVgouIq4ryTkynAiWXe6CcL90fU0soIuKeogzw3tRI3ipQHJFQUDfziIirijLAJ26hz0MNuCMSDhA7NUxK/TFFxCVFGeBOBUp+Z+DpSpRDmoWLiEuKMsCjeaxAcbSFtamViLirOAM8jxUojtaGAMagC5ki4pqiC/BCVKBAuj/mwnk1upApIq4pugB3KlDycQfm+SLhgG7mERHXFF2ARycuYOZ3Bg7pC5kHe9UfU0TcUXwBHnc2sSrEDDxIaniURFL9MUWk8IouwLtiSeZWV+S1AsXRpvZqIuKiogvwaCzFyqa6vFagOCYCXOvgIuKCogrwcxUo+V8+AVg00R9TpYQiUnhFFeDnKlDyfwEToKzM0NagShQRcUdRBXg0XrgKFEckHFAtuIi4orgCPNNGrVBLKJBeBz/cf5qz6o8pIgVWVAHuVKA0FqACxREJB9P9MftPF+yYIiJQZAEejadoL1AFisOpRNEyiogUWtEEuLWWaCxZkBt4JlseVimhiLijaAK8b3CEEwWsQHHMr61igfpjiogLiibAnSYOhbyA6YiEg9pWVkQKrmgC3KlAKWQJoaMtpFJCESm84gnweOErUBxtoQDx5DDJobMFP7aIeFv/4Ah33L+N146czPnPLpoA74oVvgLF4VzIPNSrUkIReasndh7lV9Fe5lSU5/xnF0WAu1WB4mgLpY97QHuiiMgk1lq2dHZz5ZL5rGrO/fJuUQS4U4GyosAVKI5lDbWZ/phaBxeRc147MsAbPUlu71icl59fFAHeNdGFx50ZeHVlOYvm16iUUETeYnNnN9WVZfzBlQvz8vOLIsD3xd2rQHFEwkFtKysiE86MjPHUK8f44OoW5lZX5uUYRRHgXbEkdS5VoDgioQAHE+qPKSJpT+8+TnJ4lNvXLMnbMYokwAvXhWcqkXCAwZEx4uqPKSKkl0+WNdTye231eTtGUQT4vniK9kZ31r8daq8mIo43+wZ58UA/t3csyevE0vcB3psapn9whHYX178hvQYOKiUUEdjSeYQyA5+4Jj/VJ45pA9wYU22MeckY86ox5nVjzP/KvF5vjHnWGBPNPC7I60incO4Wendn4C1zq5lTUcZBzcBFStrYuOXfdxzhPSvDNM+rzuuxZjIDHwZusdZeCVwFrDXGXA/cAzxnrW0Hnss8LzinjVqhdyE8X1mZoS0UUCmhSIn7ZTRBz6khPpnHi5eOaQPcpjnrApWZfyxwG7Ap8/om4KP5GOB0nAqUprnuVaA41B9TRDZv76YhUMUtlzTl/VgzWgM3xpQbY14B4sCz1tptQJO19jhA5rFxiu/daIzpNMZ0JhKJHA37nGgsfQHTzQoUh9Mfc2RU/TFFSlFfapif7onxsasXUVWR/0uMMzqCtXbMWnsVsBi4zhizeqYHsNbea63tsNZ2hMPhWQ5zatF4ytUbeCaLhIKMjVu6T2hTK5FS9MTOo5wds3mt/Z7sgv6KsNaeBJ4H1gIxY0wLQOYxnuvBTccrFSiONrVXEylZ1lo2d3Zz1ZL5BZtUzqQKJWyMmZ/5ugZ4H/AG8BSwIfO2DcCTeRrjlJwKFLdrwB2RiQbHKiUUKTWvHhmgK5bi9o7CzL4BKmbwnhZgkzGmnHTgb7bW/tgY8wKw2RhzN3AYWJ/HcWblVKB4ZQllfm0V9YEqzcBFStC5jataCnbMaQPcWvsacHWW1/uA9+ZjUDMVjaWom+ONChRHRKWEIiXnzMgYP3rlGB+8vIW6PG1clY2v78TsiiVpb/JGBYpD/TFFSs9PdqU3rvpkAZdPwOcB7qUKFEckHCSh/pgiJWVzZzetDbVcl8eNq7LxbYD3ZSpQVnjkAqajbeJCpmbhIqXgUO8g2w72sz7PG1dl49sA74q538Qhm4hKCUVKypYd3QXZuCob3wb4Po9VoDgm+mNqBi5S9EbHxvn3HUe4aVVj3jeuysa3Ad7lwQoUgDkV5SxeUMOBhGrBRYrdr6K9xE4NF7T2ezIfB7j3KlAckVBQa+AiJeDRiY2rsm4FlXe+DfB0Fx5vLZ84nFJC9ccUKV7OxlUfv6YwG1dl48sA70sN0zc4QrvLTRymsjwc4PTIGLFT6o8pUqye2HmU0XHr2vIJ+DTAvVqB4mgLZdqraR1cpChZa3l0ezdXL53v6mZ6vgxwpwLFqzPwiVJCrYOLFKVXuk8SjRd246psfBngTgVK89zCl+3MRPPcaqory3QhU6RIbe7spqaynA9fUbiNq7LxZYBH40lWeLQCBZz+mEEtoYgUodMjo/zo1eMF37gqG38GeCzFSo9WoDgi2tRKpCj9ZFcPqeHRgjQtno7vAtzrFSiOtlCA7hNn1B9TpMhs7uymLRRgTesCt4fivwCPxjNdeDxageKIhAOMjVsO96s/pkixONg7yEsH+1nfsdgTS7j+C/CYsweK92fgoFJCkWKypdO9jauy8V+Ax71dgeKIZGrBtQ4uUhycjatuXtVIk0fyx3cB3hXzdgWKY15tJQ3qjylSNH4ZTRBPDnO7By5eOnwX4H6oQHFEwqpEESkWj27vJhR0b+OqbHwV4H6pQHG0hQIc6NUauIjf9aaGeW5PnI9fs5jKcu/EpndGMgN+qUBxRMJBelMjDJxRf0wRP3viZWfjKm9cvHT4K8AzFSjtHuuDORX1xxTxP2stj3Z2c83S+azw2PKtvwI8U4HS4kLrotlYHnYCXMsoIn61s/sk+zywcVU2vgpwv1SgOJbU11Jm4KAqUUR8a/P2zMZVVy50eyhv46sAT3fh8cfyCaT7Yy6pr2W/llBEfCm9cdUxPnRFC8E5FW4P5218E+D9gyP0pkY828RhKm2hgGbgIj71n68dZ3BkzBMbV2XjmwDvci5g+jHAewcZH1d/TBG/2dJ5hEgoQMcy9zeuysY3AT5RQuijJRRIlxKeOTtGLDnk9lBE5AIcSKR46VA/6zuWePa6m38CPJYk6KMKFEdkYlMrLaOI+MmWHUcoLzN84ppFbg9lSj4K8BQrGv1TgeJQf0wR/xkdG+exHUe4eVWYRo9sXJWNfwI8nvT8FrLZNNVVU1NZrm1lRXzkF13pjavWe7D2e7JpA9wYs8QY83NjzB5jzOvGmC9nXq83xjxrjIlmHvO2yu/XChRw+mNqUysRP0lvXDXHUxtXZTOTGfgo8D+ttZcC1wN/Yox5B3AP8Jy1th14LvM8L5xb6Ff47AKmoy0c0Bq4iE8kksP87I04n7hmkac2rspm2tFZa49ba1/OfJ0E9gCLgNuATZm3bQI+mqcx0pWpQPHjDBxgeSjAkROnGR4dc3soIjKNJ3YeYXTcen75BC5wDdwY0wpcDWwDmqy1xyEd8kDeftfwawWKoy0cYNxCt/pjiniatZZHt3dz7bIFvviNf8YBbowJAo8BX7HWnrqA79tojOk0xnQmEonZjJH11y7hrz622ncVKA6nvdp+LaOIeNrLh0+yPzHouW1jpzKjADfGVJIO73+z1j6eeTlmjGnJ/HkLEM/2vdbae621HdbajnA4PKtBXr54Hrdd5d1azOm0altZEV/YvL2b2qpyPnSF9zauymYmVSgGuB/YY6399qQ/egrYkPl6A/Bk7odXHObVVBIKVqmUUMTDBodH+fFrx/jQ5d7cuCqbmYzyRuAOYJcx5pXMa38OfBPYbIy5GzgMrM/LCItEJBTUDFzEw/5zl7c3rspm2gC31v4amGrx+b25HU7xagsF+OmemNvDEJEpbOnsJhIOcK1HN67KxttFjkUkEg7QNzjCwGn1xxTxmv2JFNsPneB2D29clY0CvECc/pjqUi/iPVs60xtXfdzDG1dlowAvkEg4XUqodXARbxkdG+exl49w86pGGuv8da+JArxAltbXUl5mdEu9iMc8vzdBIjnsm9rvyRTgBVJVUcaSBTWagYt4zKOd6Y2rbvb4xlXZKMALqC0UYL9qwUU8I54cSm9cda33N67Kxh/V6kUiEg7ywoE+xsctZWX+udItUmiDw6P8xZOv5/2i/8Dps4yNW9Zf65/a78kU4AXUFgowdHacnlNDLJxf4/ZwRDwpOXSWux7czsuHT/DO5SHyWdUXnFPBB1Y3+2LjqmwU4AU0uT+mAlzk7QbOnGXDAy+x++gA//Tpa/jQFS1uD8nT/Lfo42PnSgm1Di5yvhODI3zmvhd5/dgA3/mMwnsmNAMvoKa5c6itKueNnqTbQxHxlL7UMJ+5bxsHege5944OX1aEuEEz8AIyxnDTqjCPbO/mF12z2xtdpNjEk0N86t4XOdg7yP0bFN4XQgFeYH/9iStY2VTHH/9gB7uPDrg9HBFX9QwM8anvvciRE2d48K41/H777HoGlCoFeIHVVVfy4J1rmFtTyece2s6RE2qzJqXp6MkzfPLeF4gnh/n+3dfxzuUht4fkOwpwFzTPq+ahu67jzNkx7nxwu3YolJJzuO80t3/3BfoHR/jXu69jTWu920PyJQW4S1Y11/G9O67lzb5BNv5rpzrWS8k42DvIJ+99gcGRUR7+/PVcvdQ/+297jQLcRe9cHuJv11/JtoP9fHXLa4yPW7eHJJJX++JJPvm9FxgeHefhz1/P5YvnuT0kX1MZoctuu2oRR0+e4Vtb97JwfjV/tu5St4ckkhd7e5J85r4XAcMjG69nZVOd20PyPQW4B/y39yzn2MkzfO8XB1g0v4bP3tDq9pBEcmr30QHuuH8bVRVlPPyF61ke9uet616jAPcAYwzf+IPL6BkY4htPvU7z3GpuvazZ7WGJ5MSr3Se54/5tBOdU8PAXrqc1s6WEXDytgXtERXkZ//jpq7l80Tz+9JGd7Dx8wu0hiVy0HW+e4I/u28bcmkoe/eINCu8cU4B7SG1VBfffuYbGumru3tTJITV/EB/bdqCPz96/jYZgFZu/eANL6mvdHlLRUYB7TCg4h4fuWoO1ljsffIm+1LDbQxK5YP+1r5c7H9xO87xqHv3iDdp9M08U4B4UCQe5b8Majg8McfemTs6MqEZc/OMXXQk+99B2ltbX8sjGG2ia669GwX6iAPeoa5ct4B8+dTWvHjnJnz6ykzHViIsPPLcnxhc2dbI8HOSHG68nXDfH7SEVNQW4h61d3cxffPgdPPvbGP/7R69jrUJcvGvr7h6+9IMdXNJSx8Nf+D3qA1VuD6noqYzQ4+66sY1jJ8/wL786yKIFNWx893K3hyTyNj969RhfefQVrlg8j02fu4651ZVuD6kkKMB94M/WXcqxgSH+70/eoHleDR+5cqHbQxKZ8PjLR/jqllfpWFbPA3etIThHsVIo+jftA2Vlhr9bfyWJU8N8dfOrNNbN4fpIg9vDEmHz9m6+/vhr3BBp4L4NHdRWKVIKSWvgPlFdWc69n72WJfU1bPx+J9GY2rKJu37w4pt87bHXeNeKEA/cuUbh7QJTyAtjHR0dtrOzs2DHK0bd/af5+D//hqryMp7443fS6GKJ1sjoOFUVmgN4yejYOKnh0bwf57GXj/J/fvxbbrmkke985hqqK8vzfsxSZozZYa3tOP91/ZXpM0vqa3nwzjXc/r0XuOuh7Tz6xRsKuubYMzDE1t3HeXp3D9sP9bOiMcja1S2sW93MJc11GGMKNpZSNjw6xsHeQaKxFPvi5/452DvIyNh4Qcbwgcua+KdPX6O/xF2kGbhP/XxvnM9v6uTGFSHu39BBZXn+/ifq7j/N05nQ3nn4JADtjUHevTLMrqMDbD/Uj7XQ2lDLusvTYX75onkK8xwYHB5lfyKVDurM4/5Eijf7BnFuDSgzsLS+lhWNQVY01tFYN4d8/6ufW13JR65amNf/7uScqWbg0wa4MeYB4MNA3Fq7OvNaPfAo0AocAm631k67+5ICPLceeekw9zy+i9s7FvPXn7gip4G5P5Fi6+4ent59nN1HTwFw2cK5rFvdzNrVLaxoPLcdaCI5zDO/7eHpXT28cKCPsXHLovk1rF3dzLrVzVyzdAFlZQrz3+Xk6ZGJWXR00oz66MkzE++pLDe0NgRob0oH9YrGIO2NQdpCAS1hFLmLCfB3Ayng+5MC/FtAv7X2m8aYe4AF1tqvTzcIBXjuffuZvfzjz/bxP963ki+/r33WP8day95Ykp/s6mHr7uN0xVIAXLVkPutWN7NudQtLG6bfjOjE4AjP7omxdXcPv472MjI2TmPdHNaubmbt6maua62nokRnbdZaEqlh9k2aTTuB3Ttpz5vqyjKWh4MTAe2E9bKGWs14S9SsAzzzza3AjycF+F7gJmvtcWNMC/C8tXbVdD9HAZ571lq+uuU1Hnv5CH/zh1ewvmPJBX3vrqMDPL27h627ezjYO4gxsKa1nnWrm/nAZc0XtQnRqaGz/PyNOE/v6uH5rjhDZ8epD1Rx6zuaWLu6mXcuDxV8/XSqteMjJ06T78XEsXHL8Oi59em6ORUsz4R0elYdpL2xjkXza/Qbi7xFrgP8pLV2/qQ/P2GtzdqZ1BizEdgIsHTp0mvffPPNWZ2ATG1kdJzPPbSdFw/08cCda3j3yvCU7x0ft+zsPpGZafdw9OQZyssMN0QaWHd5M7e+ozkv+1ecHhnlF3sT/GR3Dz/bE2NwZIy51RW87x1NrFvdwu+3h3K6DOCsHZ+/JDHV2vGS+loq8hyaxhha5lXTnplRN82do+sEMiOuBfhkmoHnT3LoLOu/+wLd/afZ/KUbuGzhuWaxo2PjvHSon627e/h/r/cQOzVMVXkZ72oPsXZ1M++/tIkFBdy3YujsGL+O9vL07h5+uifGwJmzBKrKufmSRtatbuHmS8IzrikeOH2WfYnkW5YjtHYsxUZLKCWgZ2CIj33nvxgbt2z50g0c6jvN07uO88xvY/QPjlBdWcZNKxtZd3kzN1/S6In9Ks6OjfPC/j6e3t3DM6/30Dc4wpyKMt6zMswHL2/hlksbqZtTQW9qhGg8yf5MSDtVGYnk29eO0+vGWjuW4pHrAP8boG/SRcx6a+3Xpvs5CvD829uT5A+/+xuSQ+mbOQJV5dxyaRPrVjdz06qZz2zdMDZueelgP1t3H2dr5jeFynJDbVUFA2fOTryvbk4FK5qCrAhr7VhKw8VUofwQuAkIATHgL4H/ADYDS4HDwHprbf90g1CAF0bnoX6e2HmUm1c18q4cry0XSnqt/iTPvN5Danh0IqS1diyl6KJm4LmiABcRuXBTBbgWBkVEfEoBLiLiUwpwERGfUoCLiPiUAlxExKcU4CIiPqUAFxHxKQW4iIhPFfRGHmNMAniT9F2dvQU7sPeU8vmX8rlDaZ9/KZ87XNz5L7PWvm2b0YIG+MRBjenMdldRqSjl8y/lc4fSPv9SPnfIz/lrCUVExKcU4CIiPuVWgN/r0nG9opTPv5TPHUr7/Ev53CEP5+/KGriIiFw8LaGIiPiUAlxExKcKHuDGmLXGmL3GmH2ZdmwlxRhzyBizyxjzijGmqLtbGGMeMMbEjTG7J71Wb4x51hgTzTxO2wzbj6Y4928YY45mPvtXjDEfdHOM+WKMWWKM+bkxZo8x5nVjzJczr5fKZz/V+ef88y/0jTzlQBfwfuAIsB34tLX2twUbhMuMMYeADmtt0d/QYIx5N5ACvj+pn+q3gP5J/VQXWGu/7uY482GKc/8GkLLW/q2bY8u3TKPzFmvty8aYOmAH8FHgTkrjs5/q/G8nx59/oWfg1wH7rLUHrLUjwCPAbQUegxSItfaXwPm9Um8DNmW+3kT6P+yiM8W5lwRr7XFr7cuZr5PAHmARpfPZT3X+OVfoAF8EdE96foQ8nZiHWeAZY8wOY8xGtwfjgiZr7XFI/4cONLo8nkL778aY1zJLLEW5hDCZMaYVuBrYRgl+9uedP+T48y90gGdrJV5qdYw3WmuvAdYBf5L5VVtKwz8Dy4GrgOPA37k6mjwzxgSBx4CvWGtPuT2eQsty/jn//Asd4EeAJZOeLwaOFXgMrrLWHss8xoEnSC8rlZJYZo3QWSuMuzyegrHWxqy1Y9baceBfKOLP3hhTSTq8/s1a+3jm5ZL57LOdfz4+/0IH+Hag3RjTZoypAj4FPFXgMbjGGBPIXNTAGBMAbgV2/+7vKjpPARsyX28AnnRxLAXlhFfGxyjSz94YY4D7gT3W2m9P+qOS+OynOv98fP4FvxMzUzrz90A58IC19q8KOgAXGWMipGfdABXAw8V8/saYHwI3kd5GMwb8JfAfwGZgKXAYWG+tLbqLfVOc+02kf322wCHgi86acDExxrwL+BWwCxjPvPznpNeBS+Gzn+r8P02OP3/dSi8i4lO6E1NExKcU4CIiPqUAFxHxKQW4iIhPKcBFRHxKAS4i4lMKcBERn/r/Iq/7KrLqmj4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pgd': conda)"
  },
  "interpreter": {
   "hash": "cabac2954cf654a7c1a0a2cb4143c0d9684498a99fac728f492c82ef13f7b48d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}